{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steve859/traffic_flow_prediction/blob/sensor_dataset_Duy/model/notebooks/01_pretrain_STGCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpEbhquTRlrf",
        "outputId": "dee9f10b-b7e3-4f47-ee11-d4ae1f5aec29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Cloning into 'traffic_flow_prediction'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 63 (delta 21), reused 28 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (63/63), 17.80 KiB | 5.93 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "/content/traffic_flow_prediction\n",
            "Branch 'sensor_dataset_Duy' set up to track remote branch 'sensor_dataset_Duy' from 'origin'.\n",
            "Switched to a new branch 'sensor_dataset_Duy'\n",
            "SETUP DONE\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"/content/traffic_flow_prediction\"):\n",
        "    !rm -rf /content/traffic_flow_prediction\n",
        "\n",
        "!git clone https://github.com/steve859/traffic_flow_prediction.git\n",
        "%cd traffic_flow_prediction\n",
        "!git checkout sensor_dataset_Duy\n",
        "# Setup dataset paths\n",
        "METR_H5 = \"/content/drive/MyDrive/Project Data/Dataset/metr-la.h5\"\n",
        "ADJ_PKL = \"/content/drive/MyDrive/Project Data/Dataset/adj_mx.pkl\"\n",
        "\n",
        "print(\"SETUP DONE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IphVabYTlp3",
        "outputId": "43cd8a37-f0bb-43ea-89a4-2264d04c6bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check file exists: True /content/drive/MyDrive/Project Data/Dataset/metr-la.h5\n",
            "HDF5 file keys / tree:\n",
            "df  |  Group  |  shape=None  |  dtype=None\n",
            "df/axis0  |  Dataset  |  shape=(207,)  |  dtype=|S6\n",
            "df/axis1  |  Dataset  |  shape=(34272,)  |  dtype=int64\n",
            "df/block0_items  |  Dataset  |  shape=(207,)  |  dtype=|S6\n",
            "df/block0_values  |  Dataset  |  shape=(34272, 207)  |  dtype=float64\n",
            "\n",
            "Candidate numeric datasets (name, shape, dtype):\n",
            "[('df/block0_values', (34272, 207), dtype('<f8'))]\n",
            "\n",
            "--> Loading dataset: df/block0_values\n",
            "Loaded data shape: (34272, 207) dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import os, h5py, numpy as np, pprint\n",
        "\n",
        "METR_H5 = \"/content/drive/MyDrive/Project Data/Dataset/metr-la.h5\"\n",
        "\n",
        "print(\"Check file exists:\", os.path.exists(METR_H5), METR_H5)\n",
        "if not os.path.exists(METR_H5):\n",
        "    raise FileNotFoundError(f\"File not found: {METR_H5}. Kiểm tra đường dẫn trong Drive.\")\n",
        "\n",
        "# Helper: recursively list HDF5 content\n",
        "def print_h5_tree(f):\n",
        "    def visitor(name, obj):\n",
        "        try:\n",
        "            typ = 'Group' if isinstance(obj, h5py.Group) else 'Dataset'\n",
        "            shape = getattr(obj, 'shape', None)\n",
        "            dtype = getattr(obj, 'dtype', None)\n",
        "            print(f\"{name}  |  {typ}  |  shape={shape}  |  dtype={dtype}\")\n",
        "        except Exception as e:\n",
        "            print(f\"{name}  |  <error getting info: {e}>\")\n",
        "    f.visititems(visitor)\n",
        "\n",
        "with h5py.File(METR_H5, 'r') as f:\n",
        "    print(\"HDF5 file keys / tree:\")\n",
        "    print_h5_tree(f)\n",
        "    # gather candidate datasets (numeric arrays)\n",
        "    candidates = []\n",
        "    def collect(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset):\n",
        "            shape = getattr(obj, 'shape', ())\n",
        "            if len(shape) >= 2:  # likely time x nodes\n",
        "                candidates.append((name, shape, obj.dtype))\n",
        "    f.visititems(collect)\n",
        "\n",
        "    if not candidates:\n",
        "        print(\"\\nKhông tìm thấy dataset 2D trong file. In root keys:\")\n",
        "        pprint.pprint(list(f.keys()))\n",
        "    else:\n",
        "        print(\"\\nCandidate numeric datasets (name, shape, dtype):\")\n",
        "        pprint.pprint(candidates)\n",
        "\n",
        "        # Heuristic: prefer dataset named 'speed' or with shape[1] between 100..500 (METR has 207 nodes)\n",
        "        chosen = None\n",
        "        for name, shape, dtype in candidates:\n",
        "            lower_name = name.lower()\n",
        "            if 'speed' in lower_name or 'data' in lower_name or 'traffic' in lower_name:\n",
        "                chosen = name\n",
        "                break\n",
        "        if chosen is None:\n",
        "            # pick dataset with second-dim between 100 and 500 if possible\n",
        "            for name, shape, dtype in candidates:\n",
        "                if len(shape) >= 2 and 100 <= shape[1] <= 500:\n",
        "                    chosen = name\n",
        "                    break\n",
        "        if chosen is None:\n",
        "            # fallback to first candidate\n",
        "            chosen = candidates[0][0]\n",
        "\n",
        "        print(f\"\\n--> Loading dataset: {chosen}\")\n",
        "        data = f[chosen][:]\n",
        "        print(\"Loaded data shape:\", data.shape, \"dtype:\", data.dtype)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6hGCXScTutX",
        "outputId": "1d6865e6-9f20-4b9f-c478-9b029e2520e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final data shape: (34272, 207)\n",
            "Min: 0.0 Max: 70.0\n"
          ]
        }
      ],
      "source": [
        "data = data.astype(np.float32)\n",
        "print(\"Final data shape:\", data.shape)\n",
        "print(\"Min:\", data.min(), \"Max:\", data.max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tạo Sliding Window (Pretrain METR-LA)"
      ],
      "metadata": {
        "id": "hWHLwOYonnB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Sliding window config =====\n",
        "INPUT_LEN = 12    # 12 x 5 phút = 60\n",
        "OUTPUT_LEN = 12   # dự báo 60 phút tương lai\n",
        "\n",
        "def create_sliding_window(data, input_len, output_len):\n",
        "    X, y = [], []\n",
        "    T = data.shape[0]\n",
        "\n",
        "    for t in range(T - input_len - output_len):\n",
        "        X.append(data[t:t + input_len])\n",
        "        y.append(data[t + input_len:t + input_len + output_len])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# ===== Create dataset =====\n",
        "X, y = create_sliding_window(data, INPUT_LEN, OUTPUT_LEN)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmkAtplInjp_",
        "outputId": "859bbaf7-24dd-4f0d-c149-46c60230625e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (34248, 12, 207)\n",
            "y shape: (34248, 12, 207)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chia train / val / test"
      ],
      "metadata": {
        "id": "-bvGlNmmoaGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Split ratio =====\n",
        "train_ratio = 0.7\n",
        "val_ratio   = 0.1\n",
        "\n",
        "n_samples = X.shape[0]\n",
        "\n",
        "train_size = int(n_samples * train_ratio)\n",
        "val_size   = int(n_samples * val_ratio)\n",
        "\n",
        "X_train = X[:train_size]\n",
        "y_train = y[:train_size]\n",
        "\n",
        "X_val = X[train_size:train_size + val_size]\n",
        "y_val = y[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X[train_size + val_size:]\n",
        "y_test = y[train_size + val_size:]\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Val:  \", X_val.shape, y_val.shape)\n",
        "print(\"Test: \", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCj3EveOoOGv",
        "outputId": "f76ee5d1-1309-4f39-cad8-4a34f4dcd229"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (23973, 12, 207) (23973, 12, 207)\n",
            "Val:   (3424, 12, 207) (3424, 12, 207)\n",
            "Test:  (6851, 12, 207) (6851, 12, 207)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add feature dimension"
      ],
      "metadata": {
        "id": "5cG5lwEFok-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Add feature dimension =====\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_val   = X_val[..., np.newaxis]\n",
        "X_test  = X_test[..., np.newaxis]\n",
        "\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_val:  \", X_val.shape)\n",
        "print(\"X_test: \", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u998co6tohz_",
        "outputId": "f3a6b979-1693-436d-c864-6ea50998c4d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (23973, 12, 207, 1)\n",
            "X_val:   (3424, 12, 207, 1)\n",
            "X_test:  (6851, 12, 207, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to PyTorch"
      ],
      "metadata": {
        "id": "Zj36FmSqp1rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Convert to torch tensor\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
        "\n",
        "X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "y_val_t = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
        "\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
        "\n",
        "print(\"X_train_t:\", X_train_t.shape)\n",
        "print(\"y_train_t:\", y_train_t.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtkHVJeMpv24",
        "outputId": "9cc0d154-256b-4654-e816-4ccc143ce680"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "X_train_t: torch.Size([23973, 12, 207, 1])\n",
            "y_train_t: torch.Size([23973, 12, 207])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape + Define LSTM + Train"
      ],
      "metadata": {
        "id": "etnuqIZXr0XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ===== Reshape for LSTM =====\n",
        "X_train_lstm = X_train_t.squeeze(-1)\n",
        "X_val_lstm   = X_val_t.squeeze(-1)\n",
        "\n",
        "# ===== LSTM Model =====\n",
        "class LSTMForecast(nn.Module):\n",
        "    def __init__(self, num_nodes, hidden_size=64, output_len=12):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=num_nodes,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, num_nodes * output_len)\n",
        "        self.output_len = output_len\n",
        "        self.num_nodes = num_nodes\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)              # (B, T, H)\n",
        "        out = out[:, -1, :]                # last timestep\n",
        "        out = self.fc(out)                 # (B, output_len * nodes)\n",
        "        out = out.view(-1, self.output_len, self.num_nodes)\n",
        "        return out\n",
        "\n",
        "num_nodes = X_train_lstm.shape[2]\n",
        "model = LSTMForecast(num_nodes).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ===== Train loop =====\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    perm = torch.randperm(X_train_lstm.size(0))\n",
        "\n",
        "    total_loss = 0\n",
        "    for i in range(0, X_train_lstm.size(0), BATCH_SIZE):\n",
        "        idx = perm[i:i+BATCH_SIZE]\n",
        "        xb = X_train_lstm[idx]\n",
        "        yb = y_train_t[idx]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJxs5rLOrZ5D",
        "outputId": "a78ba1be-d206-4d27-f9ba-cbc07ee3b759"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 978851.7460\n",
            "Epoch 2/10 | Train Loss: 553747.9431\n",
            "Epoch 3/10 | Train Loss: 308031.0822\n",
            "Epoch 4/10 | Train Loss: 172094.0863\n",
            "Epoch 5/10 | Train Loss: 113394.7629\n",
            "Epoch 6/10 | Train Loss: 91208.3276\n",
            "Epoch 7/10 | Train Loss: 84398.8003\n",
            "Epoch 8/10 | Train Loss: 82843.6124\n",
            "Epoch 9/10 | Train Loss: 82473.8519\n",
            "Epoch 10/10 | Train Loss: 82445.7370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save checkpoint"
      ],
      "metadata": {
        "id": "wlHo2NSUr4kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(\n",
        "    model.state_dict(),\n",
        "    \"/content/traffic_flow_prediction/model/lstm_pretrain_metrla.pt\"\n",
        ")\n",
        "print(\"Checkpoint saved successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BZZsb83rsvX",
        "outputId": "c9271ccd-b585-4afd-a6d0-31f09972631f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved successfully\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
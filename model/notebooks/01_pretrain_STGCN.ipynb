{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steve859/traffic_flow_prediction/blob/sensor_dataset_Duy/model/notebooks/01_pretrain_STGCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpEbhquTRlrf",
        "outputId": "e19faa31-51ee-434f-d935-b8f0eb4bc5cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'traffic_flow_prediction'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 77 (delta 27), reused 31 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (77/77), 2.29 MiB | 7.46 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "/content/traffic_flow_prediction\n",
            "Branch 'sensor_dataset_Duy' set up to track remote branch 'sensor_dataset_Duy' from 'origin'.\n",
            "Switched to a new branch 'sensor_dataset_Duy'\n",
            "SETUP DONE\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"/content/traffic_flow_prediction\"):\n",
        "    !rm -rf /content/traffic_flow_prediction\n",
        "\n",
        "!git clone https://github.com/steve859/traffic_flow_prediction.git\n",
        "%cd traffic_flow_prediction\n",
        "!git checkout sensor_dataset_Duy\n",
        "# Setup dataset paths\n",
        "METR_H5 = \"/content/drive/MyDrive/Project Data/Dataset/metr-la.h5\"\n",
        "ADJ_PKL = \"/content/drive/MyDrive/Project Data/Dataset/adj_mx.pkl\"\n",
        "\n",
        "print(\"SETUP DONE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IphVabYTlp3",
        "outputId": "45ee3504-1bee-4130-bc41-85e19ee4d069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check file exists: True /content/drive/MyDrive/Project Data/Dataset/metr-la.h5\n",
            "HDF5 file keys / tree:\n",
            "df  |  Group  |  shape=None  |  dtype=None\n",
            "df/axis0  |  Dataset  |  shape=(207,)  |  dtype=|S6\n",
            "df/axis1  |  Dataset  |  shape=(34272,)  |  dtype=int64\n",
            "df/block0_items  |  Dataset  |  shape=(207,)  |  dtype=|S6\n",
            "df/block0_values  |  Dataset  |  shape=(34272, 207)  |  dtype=float64\n",
            "\n",
            "Candidate numeric datasets (name, shape, dtype):\n",
            "[('df/block0_values', (34272, 207), dtype('<f8'))]\n",
            "\n",
            "--> Loading dataset: df/block0_values\n",
            "Loaded data shape: (34272, 207) dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import os, h5py, numpy as np, pprint\n",
        "\n",
        "METR_H5 = \"/content/drive/MyDrive/Project Data/Dataset/metr-la.h5\"\n",
        "\n",
        "print(\"Check file exists:\", os.path.exists(METR_H5), METR_H5)\n",
        "if not os.path.exists(METR_H5):\n",
        "    raise FileNotFoundError(f\"File not found: {METR_H5}. Kiểm tra đường dẫn trong Drive.\")\n",
        "\n",
        "# Helper: recursively list HDF5 content\n",
        "def print_h5_tree(f):\n",
        "    def visitor(name, obj):\n",
        "        try:\n",
        "            typ = 'Group' if isinstance(obj, h5py.Group) else 'Dataset'\n",
        "            shape = getattr(obj, 'shape', None)\n",
        "            dtype = getattr(obj, 'dtype', None)\n",
        "            print(f\"{name}  |  {typ}  |  shape={shape}  |  dtype={dtype}\")\n",
        "        except Exception as e:\n",
        "            print(f\"{name}  |  <error getting info: {e}>\")\n",
        "    f.visititems(visitor)\n",
        "\n",
        "with h5py.File(METR_H5, 'r') as f:\n",
        "    print(\"HDF5 file keys / tree:\")\n",
        "    print_h5_tree(f)\n",
        "    # gather candidate datasets (numeric arrays)\n",
        "    candidates = []\n",
        "    def collect(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset):\n",
        "            shape = getattr(obj, 'shape', ())\n",
        "            if len(shape) >= 2:  # likely time x nodes\n",
        "                candidates.append((name, shape, obj.dtype))\n",
        "    f.visititems(collect)\n",
        "\n",
        "    if not candidates:\n",
        "        print(\"\\nKhông tìm thấy dataset 2D trong file. In root keys:\")\n",
        "        pprint.pprint(list(f.keys()))\n",
        "    else:\n",
        "        print(\"\\nCandidate numeric datasets (name, shape, dtype):\")\n",
        "        pprint.pprint(candidates)\n",
        "\n",
        "        # Heuristic: prefer dataset named 'speed' or with shape[1] between 100..500 (METR has 207 nodes)\n",
        "        chosen = None\n",
        "        for name, shape, dtype in candidates:\n",
        "            lower_name = name.lower()\n",
        "            if 'speed' in lower_name or 'data' in lower_name or 'traffic' in lower_name:\n",
        "                chosen = name\n",
        "                break\n",
        "        if chosen is None:\n",
        "            # pick dataset with second-dim between 100 and 500 if possible\n",
        "            for name, shape, dtype in candidates:\n",
        "                if len(shape) >= 2 and 100 <= shape[1] <= 500:\n",
        "                    chosen = name\n",
        "                    break\n",
        "        if chosen is None:\n",
        "            # fallback to first candidate\n",
        "            chosen = candidates[0][0]\n",
        "\n",
        "        print(f\"\\n--> Loading dataset: {chosen}\")\n",
        "        data = f[chosen][:]\n",
        "        print(\"Loaded data shape:\", data.shape, \"dtype:\", data.dtype)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6hGCXScTutX",
        "outputId": "8ed4a7fc-e2bf-4547-cbff-16e17d55bd13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final data shape: (34272, 207)\n",
            "Min: 0.0 Max: 70.0\n"
          ]
        }
      ],
      "source": [
        "data = data.astype(np.float32)\n",
        "print(\"Final data shape:\", data.shape)\n",
        "print(\"Min:\", data.min(), \"Max:\", data.max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tạo Sliding Window (Pretrain METR-LA)"
      ],
      "metadata": {
        "id": "hWHLwOYonnB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Sliding window config =====\n",
        "INPUT_LEN = 12    # 12 x 5 phút = 60\n",
        "OUTPUT_LEN = 12   # dự báo 60 phút tương lai\n",
        "\n",
        "def create_sliding_window(data, input_len, output_len):\n",
        "    X, y = [], []\n",
        "    T = data.shape[0]\n",
        "\n",
        "    for t in range(T - input_len - output_len):\n",
        "        X.append(data[t:t + input_len])\n",
        "        y.append(data[t + input_len:t + input_len + output_len])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# ===== Create dataset =====\n",
        "X, y = create_sliding_window(data, INPUT_LEN, OUTPUT_LEN)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmkAtplInjp_",
        "outputId": "5710ae44-4f07-42ae-86d4-158b0ee95fc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (34248, 12, 207)\n",
            "y shape: (34248, 12, 207)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chia train / val / test"
      ],
      "metadata": {
        "id": "-bvGlNmmoaGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Split ratio =====\n",
        "train_ratio = 0.7\n",
        "val_ratio   = 0.1\n",
        "\n",
        "n_samples = X.shape[0]\n",
        "\n",
        "train_size = int(n_samples * train_ratio)\n",
        "val_size   = int(n_samples * val_ratio)\n",
        "\n",
        "X_train = X[:train_size]\n",
        "y_train = y[:train_size]\n",
        "\n",
        "X_val = X[train_size:train_size + val_size]\n",
        "y_val = y[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X[train_size + val_size:]\n",
        "y_test = y[train_size + val_size:]\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Val:  \", X_val.shape, y_val.shape)\n",
        "print(\"Test: \", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCj3EveOoOGv",
        "outputId": "fdb1105a-ace5-4362-a539-744e15fb1e8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (23973, 12, 207) (23973, 12, 207)\n",
            "Val:   (3424, 12, 207) (3424, 12, 207)\n",
            "Test:  (6851, 12, 207) (6851, 12, 207)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add feature dimension"
      ],
      "metadata": {
        "id": "5cG5lwEFok-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Add feature dimension =====\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_val   = X_val[..., np.newaxis]\n",
        "X_test  = X_test[..., np.newaxis]\n",
        "\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_val:  \", X_val.shape)\n",
        "print(\"X_test: \", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u998co6tohz_",
        "outputId": "8eb660e8-9628-4822-cd4d-b7297886f71f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (23973, 12, 207, 1)\n",
            "X_val:   (3424, 12, 207, 1)\n",
            "X_test:  (6851, 12, 207, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to PyTorch"
      ],
      "metadata": {
        "id": "Zj36FmSqp1rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Convert to torch tensor\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
        "\n",
        "X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "y_val_t = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
        "\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
        "\n",
        "print(\"X_train_t:\", X_train_t.shape)\n",
        "print(\"y_train_t:\", y_train_t.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtkHVJeMpv24",
        "outputId": "d85357f9-9c9c-4461-a393-a3ff6edb1af2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "X_train_t: torch.Size([23973, 12, 207, 1])\n",
            "y_train_t: torch.Size([23973, 12, 207])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape + Define LSTM + Train"
      ],
      "metadata": {
        "id": "etnuqIZXr0XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ===== Reshape for LSTM =====\n",
        "X_train_lstm = X_train_t.squeeze(-1)\n",
        "X_val_lstm   = X_val_t.squeeze(-1)\n",
        "\n",
        "# ===== LSTM Model =====\n",
        "class LSTMForecast(nn.Module):\n",
        "    def __init__(self, num_nodes, hidden_size=64, output_len=12):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=num_nodes,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, num_nodes * output_len)\n",
        "        self.output_len = output_len\n",
        "        self.num_nodes = num_nodes\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)              # (B, T, H)\n",
        "        out = out[:, -1, :]                # last timestep\n",
        "        out = self.fc(out)                 # (B, output_len * nodes)\n",
        "        out = out.view(-1, self.output_len, self.num_nodes)\n",
        "        return out\n",
        "\n",
        "num_nodes = X_train_lstm.shape[2]\n",
        "model = LSTMForecast(num_nodes).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ===== Train loop =====\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    perm = torch.randperm(X_train_lstm.size(0))\n",
        "\n",
        "    total_loss = 0\n",
        "    for i in range(0, X_train_lstm.size(0), BATCH_SIZE):\n",
        "        idx = perm[i:i+BATCH_SIZE]\n",
        "        xb = X_train_lstm[idx]\n",
        "        yb = y_train_t[idx]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJxs5rLOrZ5D",
        "outputId": "aeea06ad-1dd9-4611-9685-5cfb873aadcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 955267.9396\n",
            "Epoch 2/10 | Train Loss: 516252.1732\n",
            "Epoch 3/10 | Train Loss: 274226.3700\n",
            "Epoch 4/10 | Train Loss: 155366.1475\n",
            "Epoch 5/10 | Train Loss: 105239.1546\n",
            "Epoch 6/10 | Train Loss: 88076.0256\n",
            "Epoch 7/10 | Train Loss: 83072.0574\n",
            "Epoch 8/10 | Train Loss: 80508.1734\n",
            "Epoch 9/10 | Train Loss: 79547.9623\n",
            "Epoch 10/10 | Train Loss: 78913.8578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save checkpoint"
      ],
      "metadata": {
        "id": "wlHo2NSUr4kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(\n",
        "    model.state_dict(),\n",
        "    \"/content/traffic_flow_prediction/model/lstm_pretrain_metrla.pt\"\n",
        ")\n",
        "print(\"Checkpoint saved successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BZZsb83rsvX",
        "outputId": "e99b2831-3d35-49d3-b6f5-7dc06737163c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Load checkpoint & switch to evaluation mode =====\n",
        "model.load_state_dict(\n",
        "    torch.load(\n",
        "        \"/content/traffic_flow_prediction/model/lstm_pretrain_metrla.pt\",\n",
        "        map_location=device\n",
        "    )\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "print(\"Checkpoint loaded. Model set to eval mode.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blevfjvUUyUg",
        "outputId": "88d45a77-d89b-40af-f504-d4f4c5a636d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded. Model set to eval mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference trên validation set"
      ],
      "metadata": {
        "id": "XP4R-69bU9cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Inference (Validation) =====\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_val_lstm.to(device))\n",
        "    y_true = y_val_t.to(device)\n",
        "\n",
        "print(\"Inference done.\")\n",
        "print(\"y_pred shape:\", y_pred.shape)\n",
        "print(\"y_true shape:\", y_true.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWJ9NBksU-CH",
        "outputId": "dd6429ea-0b60-443c-fd30-89635a54d524"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference done.\n",
            "y_pred shape: torch.Size([3424, 12, 207])\n",
            "y_true shape: torch.Size([3424, 12, 207])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chuyển sang numpy + inverse scaling"
      ],
      "metadata": {
        "id": "d1Y6eUpYVe54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== To numpy & inverse scaling (if scaler exists) =====\n",
        "y_pred_np = y_pred.detach().cpu().numpy()\n",
        "y_true_np = y_true.detach().cpu().numpy()\n",
        "\n",
        "# Nếu bạn CÓ dùng scaler khi train thì bật block này\n",
        "try:\n",
        "    y_pred_np = scaler.inverse_transform(\n",
        "        y_pred_np.reshape(-1, y_pred_np.shape[-1])\n",
        "    ).reshape(y_pred_np.shape)\n",
        "\n",
        "    y_true_np = scaler.inverse_transform(\n",
        "        y_true_np.reshape(-1, y_true_np.shape[-1])\n",
        "    ).reshape(y_true_np.shape)\n",
        "\n",
        "    print(\"Inverse scaling applied.\")\n",
        "except NameError:\n",
        "    print(\"No scaler found. Skipped inverse scaling.\")\n",
        "\n",
        "print(\"y_pred_np:\", y_pred_np.shape)\n",
        "print(\"y_true_np:\", y_true_np.shape)\n"
      ],
      "metadata": {
        "id": "TXCT_8gIVbgF",
        "outputId": "861634c7-a72d-4de4-bc59-d2a6ad50399d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No scaler found. Skipped inverse scaling.\n",
            "y_pred_np: (3424, 12, 207)\n",
            "y_true_np: (3424, 12, 207)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tính metrics (MAE, RMSE, MAPE, Pearson)"
      ],
      "metadata": {
        "id": "B0C5NX7pWoIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "y_true_flat = y_true_np.reshape(-1)\n",
        "y_pred_flat = y_pred_np.reshape(-1)\n",
        "\n",
        "mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
        "rmse = np.sqrt(mean_squared_error(y_true_flat, y_pred_flat))\n",
        "mape = np.mean(np.abs((y_true_flat - y_pred_flat) / (y_true_flat + 1e-5))) * 100\n",
        "pearson = np.corrcoef(y_true_flat, y_pred_flat)[0, 1]\n",
        "\n",
        "print(f\"MAE    : {mae:.4f}\")\n",
        "print(f\"RMSE   : {rmse:.4f}\")\n",
        "print(f\"MAPE % : {mape:.2f}\")\n",
        "print(f\"Pearson: {pearson:.4f}\")\n"
      ],
      "metadata": {
        "id": "awXc72KcWlEQ",
        "outputId": "7851cf6d-4729-4229-fcb9-b27ed14ce236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE    : 9.6375\n",
            "RMSE   : 15.0299\n",
            "MAPE % : 17599828.00\n",
            "Pearson: 0.6449\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
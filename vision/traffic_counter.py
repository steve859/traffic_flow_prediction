import cv2
import numpy as np
import json
import uuid
import time
from datetime import datetime
from ultralytics import YOLO
from kafka import KafkaProducer

# Import config t·ª´ file c√πng th∆∞ m·ª•c
try:
    from config import VIDEO_CONFIGS, MODEL_PATH, TARGET_SIZE, CONF_THRESHOLD, CLASS_IDS, KAFKA_TOPIC, KAFKA_SERVER
except ImportError:
    # Fallback n·∫øu ch·∫°y t·ª´ root
    from src.vision.config import VIDEO_CONFIGS, MODEL_PATH, TARGET_SIZE, CONF_THRESHOLD, CLASS_IDS, KAFKA_TOPIC, KAFKA_SERVER

# --- C·ªú B·∫¨T/T·∫ÆT T√çNH NƒÇNG ---
ENABLE_KAFKA = False  # Set = True khi b·∫°n ƒë√£ ch·∫°y Docker Kafka
ENABLE_SIDE_BY_SIDE = True # Set = True ƒë·ªÉ xem 2 m√†n h√¨nh (G·ªëc vs AI)

# --- KH·ªûI T·∫†O KAFKA ---
producer = None
if ENABLE_KAFKA:
    try:
        producer = KafkaProducer(
            bootstrap_servers=[KAFKA_SERVER],
            value_serializer=lambda x: json.dumps(x).encode('utf-8')
        )
        print(f"‚úÖ ƒê√£ k·∫øt n·ªëi Kafka t·∫°i {KAFKA_SERVER}")
    except Exception as e:
        print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi Kafka: {e}. ƒêang ch·∫°y ch·∫ø ƒë·ªô Offline.")
        ENABLE_KAFKA = False

# --- H√ÄM TO√ÅN H·ªåC (CROSS PRODUCT) ---
def ccw(A, B, C):
    return (C[1] - A[1]) * (B[0] - A[0]) > (B[1] - A[1]) * (C[0] - A[0])

def intersect(A, B, C, D):
    """Ki·ªÉm tra vector AB c√≥ c·∫Øt ƒëo·∫°n th·∫≥ng CD kh√¥ng"""
    return ccw(A, C, D) != ccw(B, C, D) and ccw(A, B, C) != ccw(A, B, D)

def scale_line_coords(line, original_size, target_size):
    """Scale t·ªça ƒë·ªô d√≤ng k·∫ª theo t·ª∑ l·ªá resize"""
    orig_w, orig_h = original_size
    target_w, target_h = target_size
    x_scale = target_w / orig_w
    y_scale = target_h / orig_h
    start = (int(line['start'][0] * x_scale), int(line['start'][1] * y_scale))
    end = (int(line['end'][0] * x_scale), int(line['end'][1] * y_scale))
    return start, end

# --- H√ÄM X·ª¨ L√ù CH√çNH ---
def process_camera(cam_id):
    config = VIDEO_CONFIGS.get(cam_id)
    if not config:
        print(f"‚ùå Error: Kh√¥ng t√¨m th·∫•y config cho {cam_id}")
        return

    print(f"‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu x·ª≠ l√Ω: {cam_id}")
    cap = cv2.VideoCapture(config['path'])
    model = YOLO(MODEL_PATH)

    # L·∫•y th√¥ng s·ªë video g·ªëc
    orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # Scale t·ªça ƒë·ªô lines
    scaled_lines = []
    for line in config['lines']:
        s, e = scale_line_coords(line, (orig_w, orig_h), TARGET_SIZE)
        scaled_lines.append({
            "name": line['name'], "start": s, "end": e, "count": 0
        })

    track_history = {}
    counted_ids = set() # Tr√°nh ƒë·∫øm tr√πng

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            print("Video ended.")
            break

        # 1. Resize
        frame = cv2.resize(frame, TARGET_SIZE)
        
        # 2. T·∫°o b·∫£n sao cho video g·ªëc (N·∫øu b·∫≠t ch·∫ø ƒë·ªô xem 2 m√†n h√¨nh)
        if ENABLE_SIDE_BY_SIDE:
            raw_view = frame.copy()
            cv2.putText(raw_view, "ORIGINAL INPUT", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

        # 3. Tracking YOLO
        results = model.track(frame, persist=True, conf=CONF_THRESHOLD, classes=CLASS_IDS, verbose=False)
        
        # 4. V·∫Ω Line l√™n m√†n h√¨nh AI
        for line in scaled_lines:
            cv2.line(frame, line['start'], line['end'], (0, 255, 255), 2)
            cv2.putText(frame, f"{line['name']}: {line['count']}", 
                        (line['start'][0], line['start'][1] - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        # 5. X·ª≠ l√Ω logic ƒë·∫øm xe
        if results[0].boxes.id is not None:
            boxes = results[0].boxes.xywh.cpu()
            track_ids = results[0].boxes.id.int().cpu().tolist()
            class_ids = results[0].boxes.cls.int().cpu().tolist()

            for box, track_id, cls in zip(boxes, track_ids, class_ids):
                x, y, w, h = box
                center = (int(x), int(y))
                cls_name = model.names[cls]

                # Ki·ªÉm tra giao c·∫Øt
                if track_id in track_history:
                    prev_center = track_history[track_id]
                    for line in scaled_lines:
                        count_key = f"{line['name']}_{track_id}"
                        
                        if count_key not in counted_ids:
                            if intersect(prev_center, center, line['start'], line['end']):
                                # --- ƒê·∫æM TH√ÄNH C√îNG ---
                                line['count'] += 1
                                counted_ids.add(count_key)
                                
                                # G·ª≠i Kafka
                                msg = {
                                    "event_id": str(uuid.uuid4()),
                                    "camera_id": cam_id,
                                    "timestamp": datetime.now().isoformat(),
                                    "vehicle_id": track_id,
                                    "vehicle_type": cls_name,
                                    "action": "cross_line"
                                }
                                if ENABLE_KAFKA and producer:
                                    producer.send(KAFKA_TOPIC, value=msg)
                                    print(f"üì° Sent Kafka: {msg}")
                                else:
                                    print(f"‚úÖ Counted: {cls_name} (Total: {line['count']})")

                                # Visual Effect
                                cv2.circle(frame, center, 15, (0, 0, 255), -1)

                track_history[track_id] = center
                
                # V·∫Ω Box
                cv2.rectangle(frame, (int(x-w/2), int(y-h/2)), (int(x+w/2), int(y+h/2)), (0, 255, 0), 2)
                cv2.putText(frame, f"{track_id}", (int(x), int(y)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        cv2.putText(frame, "AI PROCESSING", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        # 6. Hi·ªÉn th·ªã
        final_view = frame
        if ENABLE_SIDE_BY_SIDE:
            final_view = np.hstack((raw_view, frame))

        cv2.imshow(f"Traffic Monitor - {cam_id}", final_view)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    # Ch·ªçn camera ƒë·ªÉ ch·∫°y
    process_camera("CAM_01") 
    
    # process_camera("CAM_04") # Ch·∫°y cam kh√°c